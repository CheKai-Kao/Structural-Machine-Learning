{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### package\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a63c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read data function\n",
    "def read_one_year(year, c_idx_list, timestep, datatype, \n",
    "                  height=157, width=103, keep_missing_hour=True):  \n",
    "    start_time = datetime(year, 1, 1, 0)\n",
    "    end_time = datetime(year + 1, 1, 1, 0)\n",
    "    delta = timedelta(hours=timestep)\n",
    "\n",
    "    data_tensor = []  \n",
    "    mask_tensor = []\n",
    "    current_time = start_time\n",
    "    while current_time < end_time:\n",
    "        timestamp = current_time.strftime('%Y%m%d%H')\n",
    "        path = construct_file_path(year, timestamp, datatype)   # 建立檔案完整路徑\n",
    "        grid_data = read_data_from_file(path, c_idx_list)   # 讀取檔案\n",
    "\n",
    "        if grid_data is not None:\n",
    "            valid_values = grid_data[torch.isfinite(grid_data)]    # 回傳既不是 NaN 或 ±Inf 的值\n",
    "            if valid_values.numel() > 0 and torch.all(valid_values == valid_values[0]):   # 如果tensor的數值都一樣，視為異常數據\n",
    "                data_tensor.append(torch.full((len(c_idx_list), height, width), float('nan')))\n",
    "                mask_tensor.append(0.0)\n",
    "                print(f\"All valid values are the same in file: {path}. Replacing with NaN tensor.\")\n",
    "            else:\n",
    "                data_tensor.append(grid_data)\n",
    "                mask_tensor.append(1.0)\n",
    "        else:\n",
    "            if keep_missing_hour:\n",
    "                data_tensor.append(torch.full((len(c_idx_list), height, width), float('nan')))\n",
    "                mask_tensor.append(0.0)\n",
    "\n",
    "        current_time += delta\n",
    "\n",
    "    return torch.stack(data_tensor), torch.tensor(mask_tensor)    # [total hours, C, H, W]\n",
    "\n",
    "\n",
    "def construct_file_path(year, timestamp, mode):\n",
    "    if mode == \"surfgrid\": \n",
    "        return f\"../PT_grid_data_{year}(hour)/surfgrid_RCEC_{timestamp}.pt\"\n",
    "    elif mode == \"obs\":\n",
    "        return f\"../PT_observation_{year}(hour)/observation_{timestamp}.pt\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode! Must be 'surfgrid' or 'obs'.\")\n",
    "\n",
    "\n",
    "def read_data_from_file(path, c_idx):\n",
    "    if os.path.exists(path):\n",
    "        return torch.load(path, weights_only=True)[c_idx, ...]  # [C_selected, H, W]\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file: {path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_data(year_list: list,c_idx_list: list, timestep: int, \n",
    "              datatype: str, keep_missing_hour=True):\n",
    "    \"\"\"\n",
    "    載入多個年份的資料，將其串接成一個大tensor，支援多通道輸入。\n",
    "    return：data_tensor: [8760, C, H, W], mask_tensor: [8760]\n",
    "    \"\"\"\n",
    "    all_data_tensors = []\n",
    "    all_mask_tensors = []   # 遺失或是資料不正確為0\n",
    "\n",
    "    for year in year_list:\n",
    "        data_tensor, mask_tensor = read_one_year(\n",
    "            int(year), c_idx_list, int(timestep), datatype, keep_missing_hour=keep_missing_hour\n",
    "        )\n",
    "        all_data_tensors.append(data_tensor)\n",
    "        all_mask_tensors.append(mask_tensor)\n",
    "\n",
    "    return torch.cat(all_data_tensors), torch.cat(all_mask_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a25267",
   "metadata": {},
   "outputs": [],
   "source": [
    "### loading data tensor\n",
    "data_tensor, mask_tensor = read_data(\n",
    "    year_list=[2024],\n",
    "    c_idx_list=[3, 5, 6, 7, 8],\n",
    "    timestep=1,\n",
    "    datatype='surfgrid'\n",
    ")  # data_tensor: [T_total, C, H, W], mask_tensor: [T_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert wind to u,v \n",
    "def convert_wind_to_uv(data_tensor: torch.Tensor, speed_idx: int, dir_idx: int):\n",
    "    speed = data_tensor[:, speed_idx]\n",
    "    direction = data_tensor[:, dir_idx]\n",
    "\n",
    "    if torch.any(direction < 0):\n",
    "        print(\"Skip: already converted to u/v.\")\n",
    "        return data_tensor\n",
    "\n",
    "    theta_rad = direction * torch.pi / 180.0\n",
    "    u = -speed * torch.sin(theta_rad)\n",
    "    v = -speed * torch.cos(theta_rad)\n",
    "\n",
    "    data_tensor[:, speed_idx] = u\n",
    "    data_tensor[:, dir_idx] = v\n",
    "\n",
    "    print(\"Wind converted to u/v.\")\n",
    "    return data_tensor\n",
    "\n",
    "data_tensor = convert_wind_to_uv(data_tensor, speed_idx=1, dir_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbbdd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "### class dataset\n",
    "class TimeSeriesWindowDataset(Dataset):\n",
    "    def __init__(self, data_tensor: torch.Tensor, \n",
    "                 mask_tensor: torch.Tensor, \n",
    "                 T_in: int, T: int, \n",
    "                 stride: int = 1,\n",
    "                 add_lonlat: bool = False):\n",
    "        \"\"\"\n",
    "        建立基於 sliding window 的時間序列 Dataset，並選擇性合併經緯度資訊。\n",
    "        - stride: 時間步長 (每幾個時間點取一筆樣本)\n",
    "        \"\"\"\n",
    "        self.data = data_tensor\n",
    "        self.mask = mask_tensor\n",
    "        self.T_in = T_in\n",
    "        self.T = T\n",
    "        self.stride = stride\n",
    "        self.window_size = T_in + T\n",
    "        self.add_lonlat = add_lonlat\n",
    "\n",
    "        if add_lonlat:\n",
    "            fixed_path = \"C:/Users/kevin/Documents/新 科技部計畫/PT_grid_data_2023(hour)/surfgrid_RCEC_2023010100.pt\"\n",
    "            self.grid_lonlat = self._load_and_process_lonlat(fixed_path)\n",
    "        else:\n",
    "            self.grid_lonlat = None\n",
    "\n",
    "        self.valid_indices = self._compute_valid_indices()\n",
    "\n",
    "    def _load_and_process_lonlat(self, path: str) -> torch.Tensor:\n",
    "        latlon_tensor = torch.load(path, weights_only=True)  # [C, H, W]\n",
    "        lat = latlon_tensor[0]\n",
    "        lon = latlon_tensor[1]\n",
    "\n",
    "        def normalize(tensor):\n",
    "            min_val = tensor.min()\n",
    "            max_val = tensor.max()\n",
    "            return 2 * (tensor - min_val) / (max_val - min_val) - 1\n",
    "\n",
    "        lat = normalize(lat)\n",
    "        lon = normalize(lon)\n",
    "        return torch.stack([lon, lat], dim=0)  # [2, H, W]\n",
    "\n",
    "    def _compute_valid_indices(self):\n",
    "        valid_indices = []\n",
    "        total_steps = self.data.shape[0]\n",
    "        for i in range(0, total_steps - self.window_size + 1, self.stride):  \n",
    "            window_mask = self.mask[i: i + self.window_size]\n",
    "            if window_mask.all():\n",
    "                valid_indices.append(i)\n",
    "        return valid_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = self.valid_indices[idx]\n",
    "        end_idx = start_idx + self.window_size\n",
    "        window = self.data[start_idx:end_idx]\n",
    "        \n",
    "        X = window[:self.T_in, :1]     # PM25\n",
    "        y = window[self.T_in:]\n",
    "\n",
    "        T_in, C_in = X.shape[0], X.shape[1]\n",
    "        X = X.reshape(T_in * C_in, *X.shape[2:])\n",
    "\n",
    "        T_out, C_out = y.shape[0], y.shape[1]\n",
    "        y = y.reshape(T_out * C_out, *y.shape[2:])\n",
    "\n",
    "        if self.add_lonlat and self.grid_lonlat is not None:\n",
    "            X = torch.cat([X, self.grid_lonlat], dim=0)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### build dataset/dataloader\n",
    "T_in = 1\n",
    "T = 24\n",
    "stride = 1\n",
    "\n",
    "dataset = TimeSeriesWindowDataset(data_tensor, mask_tensor, T_in, T, stride)\n",
    "\n",
    "n_sample = len(dataset)\n",
    "print(\"資料數量: \", n_sample)\n",
    "\n",
    "batch_size = 1\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d13f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check dataloader\n",
    "def check_dataloader_nan_and_range(dataloader, name=\"\"):\n",
    "    print(f\"\\n📦 檢查 DataLoader：{name}\")\n",
    "    for i, (batch_X, batch_y) in enumerate(dataloader):\n",
    "        nan_X = torch.isnan(batch_X).any().item()\n",
    "        nan_y = torch.isnan(batch_y).any().item()\n",
    "\n",
    "        print(f\"🔁 Batch {i+1}:\")\n",
    "        \n",
    "        print(f\" - X shape: {batch_X.shape}, 含 NaN: {nan_X}\")\n",
    "        if not nan_X:\n",
    "            #  batch_X 形狀為 (B, T*C, H, W)\n",
    "            C = batch_X.shape[1]\n",
    "            for c in range(C):\n",
    "                x_c = batch_X[:, c, :, :].flatten()\n",
    "                min_val = x_c.min().item()\n",
    "                max_val = x_c.max().item()\n",
    "                median_val = x_c.median().item()\n",
    "                print(f\"   - 通道 {c}: min={min_val:.2f}, median={median_val:.2f}, max={max_val:.2f}\")\n",
    "        else:\n",
    "            print(\" - X 數值範圍: (含 NaN，略過 per-channel 統計)\")\n",
    "\n",
    "        print(f\" - y shape: {batch_y.shape}, 含 NaN: {nan_y}\")\n",
    "        if not nan_y:\n",
    "            #  batch_y 形狀為 (B, T*C, H, W)\n",
    "            C = batch_y.shape[1]\n",
    "            for c in range(C):\n",
    "                y_c = batch_y[:, c, :, :].flatten()\n",
    "                min_val = y_c.min().item()\n",
    "                max_val = y_c.max().item()\n",
    "                median_val = y_c.median().item()\n",
    "                print(f\"   - 通道 {c}: min={min_val:.2f}, median={median_val:.2f}, max={max_val:.2f}\")\n",
    "        else:\n",
    "            print(\" - y 數值範圍: (含 NaN，略過 per-channel 統計)\")\n",
    "\n",
    "# ✅ 執行檢查\n",
    "check_dataloader_nan_and_range(data_loader, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load model\n",
    "from neuralop.models import FNO\n",
    "device='cuda'\n",
    "model = FNO.from_checkpoint(save_folder='checkpoint', save_name='best_FNO_test')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f84b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### model summary\n",
    "from torchinfo import summary\n",
    "\n",
    "print(summary(model, input_size=(2, 7, 157, 103)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lonlat function\n",
    "def load_and_process_lonlat(path: str) -> torch.Tensor:\n",
    "    latlon_tensor = torch.load(path, weights_only=True, map_location=device)  # [2, H, W]\n",
    "    lat = latlon_tensor[0]\n",
    "    lon = latlon_tensor[1]\n",
    "\n",
    "    def normalize(tensor):\n",
    "        min_val = tensor.min()\n",
    "        max_val = tensor.max()\n",
    "        return 2 * (tensor - min_val) / (max_val - min_val) - 1\n",
    "\n",
    "    lat = normalize(lat)\n",
    "    lon = normalize(lon)\n",
    "\n",
    "    # 合併並擴展為 [B, 2, H, W]\n",
    "    latlon = torch.stack([lat, lon], dim=0)              # [2, H, W]\n",
    "\n",
    "    return latlon\n",
    "\n",
    "# load lonlat\n",
    "lonlat = load_and_process_lonlat(\"../PT_grid_data_2023(hour)/surfgrid_RCEC_2023010100.pt\") # [2, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ae7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### autoregressive inference\n",
    "model.eval()\n",
    "\n",
    "mae_sum = [0.0 for _ in range(T)]\n",
    "rmse_sum = [0.0 for _ in range(T)]\n",
    "\n",
    "mae_high_sum = [0.0 for _ in range(T)]\n",
    "rmse_high_sum = [0.0 for _ in range(T)]\n",
    "\n",
    "count = 0\n",
    "\n",
    "# 自回歸推理 + 即時計算誤差（每一步移除 GPU 資源）\n",
    "for x, y in tqdm(data_loader, desc='Evaluating'):\n",
    "    x = x.to(device)            # [B, C, H, W]\n",
    "\n",
    "    x_current = x    # [B, 1, H, W]\n",
    "\n",
    "    for t in range(T):\n",
    "        init = t*5\n",
    "        y_current = y[:, init:init+5]\n",
    "\n",
    "        y_pm25 = y_current[:, :1]\n",
    "        cond = y_current[:, 1:].to(device)\n",
    "\n",
    "        x_cond = torch.cat([x_current, cond], dim=1)\n",
    "        \n",
    "        lonlat_batch = lonlat.unsqueeze(0).repeat(x.size(0), 1, 1, 1)  # [B, 2, H, W]\n",
    "        x_cond = torch.cat([x_cond, lonlat_batch], dim=1)   # [B, 8, H, W]\n",
    "\n",
    "        res = (model(x_cond)).detach().cpu()       # [B, 1, H, W]\n",
    "        x_current = x_current.detach().cpu()\n",
    "        pred = x_current + res\n",
    "\n",
    "        abs_error = torch.abs(pred - y_pm25)\n",
    "        squared_error = (pred - y_pm25) ** 2\n",
    "\n",
    "        mae_sum[t] += abs_error.mean()\n",
    "        rmse_sum[t] += torch.sqrt(squared_error.mean())\n",
    "\n",
    "        # ✅ 高濃度區域的誤差計算\n",
    "        mask = (y_pm25 > 35)  # [B, 1, H, W]，布林遮罩\n",
    "        if mask.sum() > 0:\n",
    "            mae_high = abs_error[mask].mean().item()\n",
    "            rmse_high = torch.sqrt(squared_error[mask].mean()).item()\n",
    "            mae_high_sum[t] += mae_high\n",
    "            rmse_high_sum[t] += rmse_high\n",
    "\n",
    "        pred = pred.to(device)\n",
    "        x_current = pred\n",
    "\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b510d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "### mean hourly errors\n",
    "\n",
    "# 平均化\n",
    "mae_avg = [val / count for val in mae_sum]\n",
    "rmse_avg = [val / count for val in rmse_sum]\n",
    "mae_high_avg = [val / count for val in mae_high_sum]\n",
    "rmse_high_avg = [val / count for val in rmse_high_sum]\n",
    "\n",
    "# 顯示結果\n",
    "for t in range(T):\n",
    "    print(f\"Step {t+1}: MAE = {mae_avg[t]:.4f}, RMSE = {rmse_avg[t]:.4f}\")\n",
    "\n",
    "for t in range(T):\n",
    "    print(f\"Step {t+1}: MAE (high) = {mae_high_avg[t]:.4f}, RMSE (high) = {rmse_high_avg[t]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot rmse, mae\n",
    "\n",
    "steps = list(range(1, T + 1))  # 時間步，從 1 到 T\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, mae_avg, marker='o', label='MAE')\n",
    "plt.plot(steps, rmse_avg, marker='s', label='RMSE')\n",
    "\n",
    "# 顯示數值標籤（MAE）\n",
    "for i, val in enumerate(mae_avg):\n",
    "    plt.text(steps[i], val, f'{val:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 顯示數值標籤（RMSE）\n",
    "for i, val in enumerate(rmse_avg):\n",
    "    plt.text(steps[i], val, f'{val:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(steps)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Error')\n",
    "plt.title('FNO MAE and RMSE per Step')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.ylim((0, 15))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, mae_high_avg, marker='o', label='High MAE (PM2.5 > 35)')\n",
    "plt.plot(steps, rmse_high_avg, marker='s', label='High RMSE (PM2.5 > 35)')\n",
    "plt.xticks(steps)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Error')\n",
    "plt.ylim((0, 20))\n",
    "plt.title('TFNO Errors in High PM2.5 Regions')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02825b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize the prediction\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# ---------- 取得樣本 ----------\n",
    "# 設定你想要的 batch 編號和 sample 編號\n",
    "target_batch_index = 110   # 取第 n 個 batch（從 0 開始）\n",
    "target_sample_index = 0  # 取 batch 中第 m 筆樣本\n",
    "\n",
    "# 迭代 dataloader，找到目標 batch\n",
    "for batch_idx, (x_batch, y_batch) in enumerate(data_loader):\n",
    "    if batch_idx == target_batch_index:\n",
    "        x_sample = x_batch[target_sample_index].unsqueeze(0).to(device)  # [1, T, H, W]\n",
    "        y_sample = y_batch[target_sample_index].unsqueeze(0).cpu()       # [1, T, H, W]\n",
    "        break\n",
    "\n",
    "# ---------- 自回歸推論 ----------\n",
    "model.eval()\n",
    "pred_list = []\n",
    "y_list = []\n",
    "with torch.no_grad():  # [1, 6, H, W]\n",
    "    x_current = x_sample\n",
    "    for t in range(T):\n",
    "        init = t*5\n",
    "        y_current = y_sample[:, init:init+5]\n",
    "\n",
    "        y_pm25 = y_current[:, :1]\n",
    "        cond = y_current[:, 1:].to(device)\n",
    "\n",
    "        x_cond = torch.cat([x_current, cond], dim=1)\n",
    "\n",
    "        lonlat_batch = lonlat.unsqueeze(0).repeat(x_sample.size(0), 1, 1, 1)  # [B, 2, H, W]\n",
    "        x_cond = torch.cat([x_cond, lonlat_batch], dim=1)\n",
    "        \n",
    "        res = (model(x_cond)).detach().cpu()\n",
    "        x_current = x_current.detach().cpu()\n",
    "        pred = x_current + res\n",
    "\n",
    "        pred_list.append(pred[0, 0])    # [H, W]\n",
    "        y_list.append(y_pm25[0, 0])\n",
    "\n",
    "        pred = pred.to(device)       \n",
    "        x_current = pred\n",
    "\n",
    "pred_tensor = torch.stack(pred_list, dim=0)         # [T, H, W]\n",
    "y_sample = torch.stack(y_list, dim=0) \n",
    "error_tensor = pred_tensor - y_sample               # [T, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# ---------- 色階準備 ----------\n",
    "pm25_values = [12.4, 30.4, 50.4, 125.4, 225.4, 325.4]\n",
    "colors = [\"#87D452\", \"#FFEB3B\", \"#F9A825\", \"#F4511E\", \"#9F48B9\", \"#6A1B1A\"]\n",
    "normalized_positions = [(v - pm25_values[0]) / (pm25_values[-1] - pm25_values[0]) for v in pm25_values]\n",
    "default_cmap = LinearSegmentedColormap.from_list(\"pm25_custom\", list(zip(normalized_positions, colors)))\n",
    "default_norm = plt.Normalize(vmin=pm25_values[0], vmax=pm25_values[-1])\n",
    "\n",
    "# ---------- 初始化圖 ----------\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(9, 4))\n",
    "im_pred = axes[0].imshow(pred_tensor[0], cmap=default_cmap, norm=default_norm)\n",
    "axes[0].set_title('Prediction')\n",
    "axes[0].axis('off')\n",
    "\n",
    "im_true = axes[1].imshow(y_sample[0], cmap=default_cmap, norm=default_norm)\n",
    "axes[1].set_title('Ground Truth')\n",
    "axes[1].axis('off')\n",
    "\n",
    "im_err = axes[2].imshow(error_tensor[0], cmap='bwr', vmin=-50, vmax=50)\n",
    "axes[2].set_title('Error')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.colorbar(im_pred, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "plt.colorbar(im_true, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "plt.colorbar(im_err, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "# ---------- 更新函數 ----------\n",
    "def update(t):\n",
    "    im_pred.set_data(pred_tensor[t])\n",
    "    axes[0].set_title(f'Prediction Step {t+1}')\n",
    "\n",
    "    im_true.set_data(y_sample[t])\n",
    "    axes[1].set_title(f'Ground Truth Step {t+1}')\n",
    "\n",
    "    im_err.set_data(error_tensor[t])\n",
    "    axes[2].set_title(f'Error Step {t+1}')\n",
    "\n",
    "    return im_pred, im_true, im_err\n",
    "\n",
    "# ---------- 動畫製作 ----------\n",
    "ani = animation.FuncAnimation(fig, update, frames=T, interval=1000, blit=False)\n",
    "\n",
    "# 儲存動畫\n",
    "ani.save(f'high_{target_batch_index}.gif', writer='pillow', fps=3)\n",
    "\n",
    "# 顯示動畫\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50050494",
   "metadata": {},
   "outputs": [],
   "source": [
    "### jet\n",
    "# ---------- 色階統一 ----------\n",
    "vmin = min(pred_tensor.min(), y_sample.min()).item()\n",
    "vmax = max(pred_tensor.max(), y_sample.max()).item()\n",
    "err_abs_max = torch.max(torch.abs(error_tensor)).item()\n",
    "\n",
    "# ---------- 畫圖 ----------\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(9, 4))\n",
    "\n",
    "# 初始化三張圖\n",
    "im_pred = axes[0].imshow(pred_tensor[0], cmap='jet', vmin=0, vmax=vmax)\n",
    "axes[0].set_title('Prediction')\n",
    "axes[0].axis('off')\n",
    "\n",
    "im_true = axes[1].imshow(y_sample[0], cmap='jet', vmin=0, vmax=vmax)\n",
    "axes[1].set_title('Ground Truth')\n",
    "axes[1].axis('off')\n",
    "\n",
    "im_err = axes[2].imshow(error_tensor[0], cmap='bwr', vmin=-50, vmax=50)\n",
    "axes[2].set_title('Error')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# 加入 colorbar\n",
    "plt.colorbar(im_pred, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "plt.colorbar(im_true, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "plt.colorbar(im_err, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "# 更新函數\n",
    "def update(t):\n",
    "    im_pred.set_data(pred_tensor[t])\n",
    "    axes[0].set_title(f'Prediction Step {t+1}')\n",
    "    \n",
    "    im_true.set_data(y_sample[t])\n",
    "    axes[1].set_title(f'Ground Truth Step {t+1}')\n",
    "    \n",
    "    im_err.set_data(error_tensor[t])\n",
    "    axes[2].set_title(f'Error Step {t+1}')\n",
    "    \n",
    "    return im_pred, im_true, im_err\n",
    "\n",
    "# ---------- 動畫製作 ----------\n",
    "ani = animation.FuncAnimation(fig, update, frames=T, interval=1000, blit=False)\n",
    "\n",
    "# 儲存動畫\n",
    "ani.save(f'{target_batch_index}.gif', writer='pillow', fps=3)\n",
    "\n",
    "# 顯示動畫\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myPytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
